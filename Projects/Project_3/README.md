# Проект 3. Предсказание рейтига отелей на Booking.

## Оглавление  
[1. Описание проекта](https://github.com/StasBard/SF_DataScience/tree/master/Projects/Project_3#1-%D0%BE%D0%BF%D0%B8%D1%81%D0%B0%D0%BD%D0%B8%D0%B5-%D0%BF%D1%80%D0%BE%D0%B5%D0%BA%D1%82%D0%B0)  
[2. Решаемая задача](https://github.com/StasBard/SF_DataScience/tree/master/Projects/Project_3#2-%D1%80%D0%B5%D1%88%D0%B0%D0%B5%D0%BC%D0%B0%D1%8F-%D0%B7%D0%B0%D0%B4%D0%B0%D1%87%D0%B0)  
[3. Краткая информация о данных](https://github.com/StasBard/SF_DataScience/tree/master/Projects/Project_3#3-%D0%BA%D1%80%D0%B0%D1%82%D0%BA%D0%B0%D1%8F-%D0%B8%D0%BD%D1%84%D0%BE%D1%80%D0%BC%D0%B0%D1%86%D0%B8%D1%8F-%D0%BE-%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85)  
[4. Этапы работы над проектом](https://github.com/StasBard/SF_DataScience/tree/master/Projects/Project_3#4-%D1%8D%D1%82%D0%B0%D0%BF%D1%8B-%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D1%8B-%D0%BD%D0%B0%D0%B4-%D0%BF%D1%80%D0%BE%D0%B5%D0%BA%D1%82%D0%BE%D0%BC)  
[5. Результаты](https://github.com/StasBard/SF_DataScience/tree/master/Projects/Project_3#5-%D1%80%D0%B5%D0%B7%D1%83%D0%BB%D1%8C%D1%82%D0%B0%D1%82%D1%8B)  
[6. Выводы](https://github.com/StasBard/SF_DataScience/tree/master/Projects/Project_3#6-%D0%B2%D1%8B%D0%B2%D0%BE%D0%B4%D1%8B)  


### 1. Описание проекта    
Представим, что я работаю дата-сайентистом в компании Booking. Одна из проблем компании — это нечестные отели, которые накручивают себе рейтинг. Одним из способов обнаружения таких отелей является построение модели, которая предсказывает рейтинг отеля. Если предсказания модели сильно отличаются от фактического результата, то, возможно, отель ведёт себя нечестно, и его стоит проверить.  

:bookmark_tabs: [к оглавлению](https://github.com/StasBard/SF_DataScience/tree/master/Projects/Project_3#%D0%BE%D0%B3%D0%BB%D0%B0%D0%B2%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5)  


### 2. Решаемая задача    
С помощью изученных методов разведовательного анализа (EDA) требуется подготовить имеющуюся базу данных об отелях с сайта Booking.com к подаче на вход модели RandomForestRegressor для обучения и предсказания рейтинга отелей из тестовой выборки. 

**Условия решения задачи:**  
Задача реализована в форме соревнования на платформе kaggle.  

Автором задания подготовлен baseline - jupyter-notebook с основыми этапами обработки данных. В ходе работы над задачей требуется наполнить эти этапы содержимым: выполнить очистку данных, провести разведовательный анализ, обучить модель и предсказать рейтинги тестовой выборки отеля, при этом получив значение итоговой метрики средней абсолютной ошибки ниже 13,5%.

Результаты предсказания в файле submission.csv загружаются на платформу kaggle для оценки рейтинга работы и добавления студента в рейтинг победителей. Ссылка на публичный ноутбук отправляется на проверку ментору. Кроме этого, файл ноутбука следует разместить на платформе GitHub, сопроводив описанием, и также предоставить ссылку на проверку ментору.

В процессе решения студент должен продемонстрировать владение методами разведовательного анализа, умение выдвигать и проверять гипотезы, сопровождать их визуализацией и выводами, оформлять код в соответствии со стандартами PEP-8.

**Метрика качества**     
Выполненная задача должна соответствовать следующим критериям:
- Качество кода (соблюдение стандартов оформления PEP-8, комментирование кода, README к проекту). Оформление проекта на GitHub, GitLab, Kaggle.  
- Очистка данных.  
- Исследование данных (качество визуализации, наличие идей, гипотез, комментариев).  
- Генерация признаков.  
- Отбор признаков.  
- Преобразование признаков.  
- Качество решения: результат метрики MAPE (желательно ниже 13,5%).

За каждый критерий можно получить 3 балла:  
0 - Задание не выполнено или результатами работы невозможно воспользоваться на практике.  
1 - Есть большие неточности в выполнении задания.  
2 - Задача решена, требуются минимальные доработки.  
3 - Задача решена полностью, результат можно использовать на практике.  

Максимально можно набрать таким образом: 21 балл.  
Для успешного выполнения проекта необходимо набрать 12 баллов.  

**Практикуемые навыки**     
- усвоить последовательность разведовательного анализа данных;
- улучшить понимание статистических тестов для отбора сгенерированных данных;    
- развивать способность выдвигать гипотезы о зависимостях в данных, подтверждать или опровергать их, делать выводы;  
- добиться заданной величины метрики MAPE лишь с помощью подготовки данных без изменения параметров модели;  
- практиковать работу на платформах kaggle и GitHub (посредством добавления отчета о проекте в портфолио);  
- практиковать навыки использования языка разметки MarkDown;  
- улучшить навыки составления эффективного воспроизводимого код на Python в соответствии с PEP-8.  

:bookmark_tabs: [к оглавлению](https://github.com/StasBard/SF_DataScience/tree/master/Projects/Project_3#%D0%BE%D0%B3%D0%BB%D0%B0%D0%B2%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5)  


### 3. Краткая информация о данных  
Для работы над проектом предоставлена база отелей сервиса Booking.com в виде тренировочного и тестового датафреймов, отличающихся наличием признака пользовательской оценки отеля reviewer_score. Описание всех признаков содержится в начале ноутбука с решением.  

В ходе работы разрешается использовать любые внешние источники для генерирования дополнительных признаков в данных.
  
:bookmark_tabs: [к оглавлению](https://github.com/StasBard/SF_DataScience/tree/master/Projects/Project_3#%D0%BE%D0%B3%D0%BB%D0%B0%D0%B2%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5)  


### 4. Этапы работы над проектом  
1. Знакомство с данными.  
2. Очистка и подготовка данных.  
3. Разведывательный анализ.  
4. Анализ работодателей.  
5. Обучение модели и оценка результатов.  
6. Предсказание рейтинга отелей.  
7. Оформление проекта на kaggle и GitHub.  

:bookmark_tabs: [к оглавлению](https://github.com/StasBard/SF_DataScience/tree/master/Projects/Project_3#%D0%BE%D0%B3%D0%BB%D0%B0%D0%B2%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5)  


### 5. Результаты  
В ходе работы над проектом последовательно пройдены все этапы обработки данных:
- несмотря на то, что входные данные представлены в хорошо подготовленной форме, проведена дополнительная их очистка, что не могло не повлиять на улучшение итоговой метрики;  
- данные исследованы, намечены шаги EDA, обосновано использование/не использование тех или иных методов обработки;  
- проведен разведовательный анализ данных:  
    - сгенерированы новые признаки (в том числе с использованием внешних источников),  
    - проведено снижение размерности признаков путем кодирования,  
    - оценена их значимость, мультиколлинеарность и принято решение об удалении или оставлении в датафрейме;  
- достигнуто целевое значение итоговой метрики MAPE (12,56% в ноутбуке);  
- каждый этап сопровожден развернутыми комментариями и выводами, визуализацией данных;  
- файл sumbission.csv с предсказанными рейтингами загружен на kaggle;  
- проект в виде ноутбука оформлен на [kaggle](https://www.kaggle.com/stasbard/project-3-booking-reviews) и [GitHub](https://github.com/StasBard/SF_DataScience/blob/master/Projects/Project_3/Project_3_EDA_Booking_reviews.ipynb). 

**Эволюция коммитов.**  
Улучшение метрики MAPE достигалось с помощью разведовательного анализа. По рекомендации ментора, была применена библиотека анализа естественного языка nltk. При этом в первом подходе из возвращаемых оценок использовались лишь совокупные для отрицательных и положительных отзывов, которые складывались для образование одного признака. Этот прием не дал желаемого улучшения MAPE, в результате чего было принято решение использовать все четыре составляющие для каждого отзыва: положительную, нейтральную, отрицательную и совокупную. Первая версия сабмита сразу содержит именно такое решение.  

На втором сабмите было обнаружено, что излишнее удаление даже кореллирующих признаков негативно сказывается на MAPE, что дало понимание необходимости сохранять баланс с удалении и сохранении даже сильно связанных признаков.  

Последние три сабмита - по сути тонкая доработка финальных результатов и оформление ноутбука, разница между ними невелика. Однако тут открылось негативное влияние метода MinMaxScaler на предсказательный рейтинг с помощью модели RandomForestRegressor, о чем предупреждал ментор на вебинаре: рейтинги оказались на порядок меньше. Я не заметил этого, и загрузил файл на платформу, в результате чего получил оценку 89,7%. Для исправления ситуации я нашел два способа: умножение всех предсказанных оценок на 10 или отказ от использования метода MinMaxScaler. Последнему было отдано предпочтение, учитывая его незначительный вклад в улучшение метрики.  

Наконец, интересным стало открытие, что небольшая ошибка в координате центра города (модуль долготы для Лондона) при расчете признака расстояния до отеля приводил к наилучшей итоговой метрике (12,54%). Без понимания устройства модели, мне это показалось странным, поскольку модель подбирает коэффициенты, обусловливающие рейтинг теми или иными признаками - какая разница будет расстояние до центра составлять 3 км или 2 км, к примеру. Вероятно, мое понимание неверное, и оно углубится в следующем обучающем модуле по изучению машинного обучения. Пока же пришлось исправить ошибку и довольствоваться чуть худшим результатом.

:bookmark_tabs: [к оглавлению](https://github.com/StasBard/SF_DataScience/tree/master/Projects/Project_3#%D0%BE%D0%B3%D0%BB%D0%B0%D0%B2%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5)  


### 6. Выводы  
1. Несмотря на кажущуюся простоту задачи (очистка данных и генерирование новых признаков за счет здравого смысла и известных инструментов библиотек python без изучения устройства модели машинного обучнения), проект оказался довольно трудоемким и сложным, и занял свыше 40 часов, включая время на изучение учебных материалов и просмотр вводного вебинара.  
2. С точки зрения оформления и визуализации он уступает предыдущим проектам, основной упор которых делался именно на эту составляющую. Впрочем, никто не ограничивал нас в использовании всего имеющегося арсенала приемов визуализации, однако поскольку основная задача была в том, чтобы обучить моделить и добиться улучшения метрики MAPE, на это были брошены все силы. И с учетом затраченного времени, другим составляющим проекта пришлось уделить меньше внимания.  
3. Вместе с тем, данный проект показал значимость подготовки данных перед обучением модели и позволил потренировать полученные навыки разведывательного анализа.  
4. Сюрпризом (на который намекал во время вводного вебинара ментор) стало взаимодействие методов нормализации и стандартизации данных с моделью машинного обучения RandomForestRegressor: использование первых либо ухудшало значение метрики MAPE, либо улучшало ее незначительно, но при этом искажало получаемые предсказания. В результате, от использования этих методов в данном проекте пришлось отказаться.  
5. Особой ценностью проекта стала его реализация на платформе kaggle в атмосфере здоровой конкуренции за высокий рейтинг. Студенты получили действительный инструмент повышения своих навыков Data Scientist'а и, следовательно, шансов на трудоустройство через участие в реальных интересных соревнованиях.  

:bookmark_tabs: [к оглавлению](https://github.com/StasBard/SF_DataScience/tree/master/Projects/Project_3#%D0%BE%D0%B3%D0%BB%D0%B0%D0%B2%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5)  


Если информация по проекту представляется Вам интересной и полезной, я буду Вам благодарен за отметку моего репозитория и профиля на GitHub звездами ⭐️⭐️⭐️! А также, прошу поставить upvote моему ноутбуку на kaggle. Спасибо!