# Проект 1. Анализ резюме из HeadHunter.

## Оглавление  
[1. Описание проекта]()  
[2. Решаемая задача]()  
[3. Краткая информация о данных]()  
[4. Этапы работы над проектом]()  
[5. Результаты]()  
[6. Выводы]()  


### 1. Описание проекта    
Анализ базы резюме HeadHunter с целью ее подготовки для использования в модели машинного обучения, определяющей примерный уровень заработной платы, подходящей соискателю на основании информации, которую тот указал о себе.

:bookmark_tabs: [к оглавлению]()


### 2. Решаемая задача    
Проблематика задачи: часть соискателей не указывает желаемую заработную плату, когда составляет своё резюме.
Поэтому имеющуюся в распоряжении базу резюме с сайта поиска вакансий hh.ru необходимо преобразовать, исследовать и очистить.

**Условия решения задачи:**  
В ходе каждого этапа работы над проектом необходимо выполнить блоки практических заданий в jupyter-notebook по предложенному шаблону и ответить на контрольные вопросы на платформе SkillFactory. Посредством ответов на эти вопросы проверяется верность решений в заданиях.
Задания выполняются последовательно.

С целью разведывательного анализа разрешено использовать любую из изученных библиотек визуализации: Matplotlib, Seaborn и Plotly. Однако рекомендуется выбрать Plotly ввиду ее интерактивности.

В остальном разрешается использовать только изученные в курсе переменные, структуры данных, циклы, функции, библиотеки, методы, правила и стандарты (включая PEP 8).

**Метрика качества**     
- За ответы на все контрольные вопросы на платформе можно максимально набрать 30 баллов.
- За выводы по разведывательному анализу в jupyter-notebook можно получить еще 10 баллов: 8 основных и 2 дополнительных (за проверку собственных гипотез).  

Итого: 40 баллов.
Для успешного выполнения проекта необходимо набрать 21 балл.

**Практикуемые навыки**     
- закрепить последовательность этапов предобработки данных;
- улучшить навыки использования изученных методов для преобразования данных;
- углубить знания методов библиотек визуализации и различных типов графиков для исследования зависимостей в данных;
- улучшить навык формулирования выводов на основе проанализированной информации;
- развить способность выдвигать гипотезы о зависимостях в данных, подтверждать или опровергать их с помощью графиков;
- улучшить навыки использования языка разметки MarkDown;
- улучшить навыки работы с IDE VS Code, Git, GitHub (посредством добавления отчета о проекте в портфолио);
- улучшить навыки составления эффективного воспроизводимого код на python в соответствии с PEP 8.

:bookmark_tabs: [к оглавлению]()


### 3. Краткая информация о данных  
Для работы предоставляется база резюме, выгруженная с сайта поиска вакансий hh.ru.
Ввиду ее большого размера (434,4 Мб) она не может быть загружена на сайт GitHub, поэтому для воспроизведения кода данного проекта читателю предлагается скачать базу по [ссылке](https://drive.google.com/file/d/1_l4Bbc1xrUnQyDTsLzRP0EOaz-myM3yK/view?usp=share_link) и сохранить ее в папку data/ проекта.

Дополнительно предоставляетя таблица котировок валют с целью конвертации желаемых зарплат соискателей из базы. Эта таблица находится в [папке проекта]() и не требует дополнительных действий.
  
:bookmark_tabs: [к оглавлению]()


### 4. Этапы работы над проектом  
1. Базовый анализ структуры данных.
2. Преобразование данных.
3. Разведывательный анализ.
4. Очистка данных.
5. Оформление проекта и загрузка на GitHub.

:bookmark_tabs: [к оглавлению]()


### 5. Результаты  
По итогам работы над проектом:
- предоставлены ответы на все контрольные вопросы на платформе SkillFactory, за что начислено 30 баллов;
- сформулированы развернутые выводы по 8-ми обязательным пунктам разведывательного анализа, а также по 3-м собственным (один - бонусный);
- подготовлен [отчет]() об анализе базы данных резюме в формате jupiter-notebook с рекомендациями, на какие признаки стоит обратить внимание при создании модели машинного обучения.
- проведена очистка данных, позволяющая подать обработанную базу резюме на вход модели обучения.

:bookmark_tabs: [к оглавлению]()


### 6. Выводы  
В процессе работы над проектом укрепилось понимание важности анализа и предобработки данных перед их последующим использованием в моделях машинного обучения, бизнесе; обнаружились возможные "подводные камни" неполноты данных, а вместе с ними отработаны приемы обработки и очистки данных; расширились знания способов визуализации взаимосвязей признаков в данных; успешно реализованы все обозначенные практики.

:bookmark_tabs: [к оглавлению]()


Если информация по проекту представляется Вам интересной и полезной, я буду Вам благодарен за отметку моего репозитория и профиля звездами ⭐️⭐️⭐️!